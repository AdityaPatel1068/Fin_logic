{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "tickers = ['AMZN', 'GOOG']\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create a dictionary to store DataFrames for each ticker\n",
    "ticker_dfs = {}\n",
    "\n",
    "news_tables = {}\n",
    "for ticker in tickers:\n",
    "    url = finviz_url + ticker\n",
    "\n",
    "    req = Request(url=url, headers={'user-agent': 'my-app'})\n",
    "    response = urlopen(req)\n",
    "\n",
    "    html = BeautifulSoup(response, features='html.parser')\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "# Parse news data and create DataFrames for each ticker\n",
    "for ticker, news_table in news_tables.items():\n",
    "    parsed_data = []\n",
    "    if news_table:\n",
    "        for row in news_table.findAll('tr'):\n",
    "            try:\n",
    "                date_time_td = row.find_all('td')[0].text.strip() if len(row.find_all('td')) > 0 else ''\n",
    "                title_element = row.find_all('td')[1].find('a') if len(row.find_all('td')) > 1 else None\n",
    "\n",
    "                if title_element:\n",
    "                    title = title_element.text.strip()\n",
    "                    link = title_element.get('href')\n",
    "\n",
    "                    # Parse date and time\n",
    "                    if 'Today' in date_time_td:\n",
    "                        date = datetime.now().strftime('%Y-%m-%d')\n",
    "                        time = date_time_td.replace('Today', '').strip()\n",
    "                    else:\n",
    "                        date_parts = date_time_td.split(' ')\n",
    "                        if len(date_parts) == 2:\n",
    "                            date = datetime.now().strftime('%Y-%m-%d')  # Placeholder if date is not included\n",
    "                            time = date_parts[1]\n",
    "                        else:\n",
    "                            date = ''\n",
    "                            time = ''\n",
    "                    \n",
    "                    # Combine date and time into datetime\n",
    "                    date_time = f\"{date} {time}\"\n",
    "                    \n",
    "                    # Append parsed data\n",
    "                    parsed_data.append([ticker, date_time, title, link])\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing row: {e}\")\n",
    "\n",
    "    # Create DataFrame and store in dictionary\n",
    "    df = pd.DataFrame(parsed_data, columns=['Ticker', 'DateTime', 'Title', 'URL'])\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'], format='%Y-%m-%d %I:%M%p', errors='coerce')\n",
    "    df = df.dropna(subset=['DateTime'])\n",
    "    ticker_dfs[ticker] = df\n",
    "\n",
    "# Function to extract text from a URL\n",
    "def extract_text_from_url(url):\n",
    "    try:\n",
    "        req = Request(url=url, headers={'user-agent': 'my-app'})\n",
    "        response = urlopen(req)\n",
    "        html = BeautifulSoup(response, features='html.parser')\n",
    "        paragraphs = html.find_all('p')\n",
    "        text = ' '.join([p.get_text() for p in paragraphs])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Update each DataFrame with the full news text\n",
    "for ticker, df in ticker_dfs.items():\n",
    "    df['News'] = df['URL'].apply(lambda url: extract_text_from_url(url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame for AMZN:\n",
      "   Ticker            DateTime  \\\n",
      "0    AMZN 2024-08-30 17:08:00   \n",
      "14   AMZN 2024-08-30 20:49:00   \n",
      "34   AMZN 2024-08-30 20:29:00   \n",
      "49   AMZN 2024-08-30 18:22:00   \n",
      "66   AMZN 2024-08-30 20:24:00   \n",
      "\n",
      "                                                Title  \\\n",
      "0                        Stocks to Watch in September   \n",
      "14  7 Best Fast Money Stocks To Buy According To H...   \n",
      "34        4 Key Takeaways From Nvidia's Earnings Call   \n",
      "49  Kelce brothers podcast, private-equity vote: L...   \n",
      "66  Stock-Split Watch: 3 Top Stocks That Look Read...   \n",
      "\n",
      "                                                  URL  \\\n",
      "0   https://www.investopedia.com/stocks-to-watch-s...   \n",
      "14  https://www.insidermonkey.com/blog/7-best-fast...   \n",
      "34  https://www.investopedia.com/4-key-takeaways-f...   \n",
      "49  https://finance.yahoo.com/video/kelce-brothers...   \n",
      "66  https://finance.yahoo.com/m/7220beb0-033f-3524...   \n",
      "\n",
      "                                                 News  \n",
      "0   Editors' Picks for Companies That Are Likely t...  \n",
      "14  Our #1 AI Stock Pick is on a steep discount - ...  \n",
      "34  Investopedia / Julie Bang  After Nvidia (NVDA)...  \n",
      "49  NFL stars and brothers Travis and Jason Kelce ...  \n",
      "66  Stock splits attract a lot of attention among ...  \n",
      "Updated DataFrame for GOOG:\n",
      "   Ticker            DateTime  \\\n",
      "0    GOOG 2024-08-30 17:08:00   \n",
      "20   GOOG 2024-08-30 22:52:00   \n",
      "49   GOOG 2024-08-30 22:34:00   \n",
      "73   GOOG 2024-08-30 17:52:00   \n",
      "89   GOOG 2024-08-30 22:02:00   \n",
      "\n",
      "                                                Title  \\\n",
      "0                        Stocks to Watch in September   \n",
      "20  Google to open second data center in Latin Ame...   \n",
      "49  Why Is Nvidia (NVDA) Stock Crashing After Beat...   \n",
      "73       Analysts are Recommending These 10 AI Stocks   \n",
      "89  Watch These Apple Stock Price Levels Ahead of ...   \n",
      "\n",
      "                                                  URL  \\\n",
      "0   https://www.investopedia.com/stocks-to-watch-s...   \n",
      "20  https://finance.yahoo.com/news/google-open-sec...   \n",
      "49  https://www.insidermonkey.com/blog/why-is-nvid...   \n",
      "73  https://www.insidermonkey.com/blog/analysts-ar...   \n",
      "89  https://www.investopedia.com/watch-these-apple...   \n",
      "\n",
      "                                                 News  \n",
      "0   Editors' Picks for Companies That Are Likely t...  \n",
      "20  (Reuters) - Alphabet's Google said on Thursday...  \n",
      "49  Our #1 AI Stock Pick is on a steep discount - ...  \n",
      "73  Our #1 AI Stock Pick is on a steep discount - ...  \n",
      "89   Apple (AAPL) shares are likely to remain in f...  \n"
     ]
    }
   ],
   "source": [
    "# Print updated DataFrames for verification\n",
    "for ticker, df in ticker_dfs.items():\n",
    "    print(f\"Updated DataFrame for {ticker}:\")\n",
    "    print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
